Recent machine learning advancements have allowed us to attempt training a newer model, the Vision Transformer (ViT), on a dataset of Colorectal cancer tissue images. Using the Colorectal cancer histology dataset, we can classify each of the textures of the cancerous tissue (as well as none, or the case of no cancer present).

In this experiment, we have demonstrated classification for colon histology images using a pre- trained ViT model. The custom ColonHistologyDataset class, built using PyTorch, enabled efficient handling and transformation of the images. This transformation is a simple resizing of the dataset to images of size 224x224 to match the size of the pre-trained model’s dataset.

Our custom ViTForImageClassification model, using pre-trained ViT weights from Hugging Face, showed exceptional performance in image classification. The training process, utilizing hyperparameters and the Adam optimizer, effectively minimized the cross-entropy loss. The model achieved impressive test and validation accuracies of 97% and 96%, respectively. These results reflect the model’s robustness and reliability in classifying colon histology images.
Vision Transformers have proved to be a valid classifier for this dataset. Future work could include different kinds of medical images to be trained, as well as other vision transformers and classifiers for in depth comparison. A more complex vision transformer model can also be developed, with more layers than used in this implementation.
